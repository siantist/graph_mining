{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weight, given input vector q (quantity assoc to node i)\n",
    "\n",
    "def weights(A, q, beta):\n",
    "    n = len(A)\n",
    "    w = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            w[i,j] = np.pow(q[i]*q[j], beta)*A[i,j]\n",
    "    \n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df74689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the weights function\n",
    "\n",
    "weights(A1, q1, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b50900",
   "metadata": {},
   "source": [
    "The most popular family of graph kernels is probably the random walk kernels which quantify the similarity between a pair of graphs based on the number of common walks in the two graphs.\n",
    "\n",
    "The -step random walk kernel compares random walks up to length  in the two graphs. The most widely-used kernel from this family is the geometric random walk kernel [GartnerFW03] which compares walks up to infinity assigning a weight $\\lambda^k, \\lambda<1$ to walks of length  in order to ensure convergence of the corresponding geometric series. \n",
    "\n",
    "\n",
    "file:///Users/sian/Downloads/BloemReddy_columbia_0054D_13818.pdf\n",
    "\n",
    "pg 46: random walk matrix: prob of reaching v_j after k steps is [W^k]_{ij}\n",
    " - how does the cycle basis fit into this theory ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the kronecker product of the weight matrices\n",
    "\n",
    "\n",
    "np.kron(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact kernel is (q1 x q2 ) ( W_1^T x W_2^T)^{ell}(p1 x p2)\n",
    "\n",
    "# number of length ell common walks on the direct product graph \n",
    "ell = 5\n",
    "\n",
    "np.pow(np.kron(w1.T, w2.T), ell)\n",
    "# idea: choose ell to optimize the score? How is this determined ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b711233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the output of the following\n",
    "if self.p is not None:\n",
    "    P = np.eye(XY.shape[0])\n",
    "    S = self.mu_[0] * P\n",
    "    for k in self.mu_[1:]:\n",
    "        P = np.matmul(P, XY)\n",
    "        S += k*P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = inv(np.identity(s) - self.lamda*XY).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe62ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ccf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ysig/GraKeL/tree/master/grakel\n",
    "\n",
    "def pairwise_operation(self, X, Y):\n",
    "    \n",
    "    XY = np.kron(X, Y)\n",
    "    \n",
    "    # p = number of steps \n",
    "    if self.p:\n",
    "        S= np.pow(np.kron(w1.T, w2.T), ell)\n",
    "    \n",
    "    return np.sum(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b791f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the above function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c695f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grakel\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from grakel import Graph\n",
    "edges = {1: [2, 3], 2: [1], 3: [1]}\n",
    "G = Graph(edges)\n",
    "\n",
    "edges2 = {1:[2,3], 2:[1,3], 3:[1,2,4,5,6], 4:[3,5], 5:[3,4,6], 6:[3,5]}\n",
    "\n",
    "G2 = Graph(edges2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96ae3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edges_graph1 = {1:[2], 2:[1,3,4,5], 3:[2,4,6], 4:[2,3,5,6], 5:[2,4,6], 6:[3,4,5]}\n",
    "edges_graph1_edge_diff= {1:[2,3], 2:[1,3,4,5], 3:[1,2,4,6], 4:[2,3,5,6], 5:[2,4,6], 6:[3,4,5]}\n",
    "\n",
    "graph1 = Graph(edges_graph1)\n",
    "\n",
    "graph1_copy = Graph(edges_graph1)\n",
    "\n",
    "graph1_edge_diff = Graph(edges_graph1_edge_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355f6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grakel.kernels import RandomWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53082a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_kernel = RandomWalk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ef5f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.04166667]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_kernel.fit_transform([G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed4b76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.39801372]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_kernel.transform([G2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ba5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# program the common nbd product \n",
    "\n",
    "def common_nbd_product(A, B, v_labels1, v_labels2):\n",
    "    \n",
    "    # vertices V(A) x V(B)\n",
    "    n = len(A)\n",
    "    \n",
    "    vertices1x2 = {}\n",
    "    inverse_vertices1x2= {}\n",
    "    ind=0\n",
    "    \n",
    "    v1 = 0\n",
    "    for lab1 in v_labels1:\n",
    "        v2 = 0\n",
    "        for lab2 in v_labels2:\n",
    "            \n",
    "            if lab1 == lab2:\n",
    "                \n",
    "                pair = (v1, v2)\n",
    "\n",
    "                vertices1x2[ind] = pair\n",
    "                inverse_vertices1x2[pair] = ind\n",
    "            ind= ind+1\n",
    "            v2 +=1\n",
    "        v1+=1\n",
    "    \n",
    "    # make vertices as pairs of all v(A) x v(B)\n",
    "    n1 = len(A)\n",
    "    n2 = len(B)\n",
    "    \n",
    "    v3 = []\n",
    "    \n",
    "    list1 = np.range(n1)\n",
    "    list2 = np.range(n2)\n",
    "    # generate all unique pairs \n",
    "    for i in itertools.product(list1, list2):\n",
    "        \n",
    "        print(i)\n",
    "        v3.append(i)\n",
    "        \n",
    "    \n",
    "    for ver1 in v3:\n",
    "        \n",
    "        for ver2 in v3:\n",
    "        \n",
    "            a1 = ver1[0]\n",
    "            a2 = ver1[1]\n",
    "            \n",
    "            b1 = ver2[0]\n",
    "            b2 = ver2[1]\n",
    "            # check the edges here\n",
    "            e1 = np.nonzero(A[a1]) #np.where(A[i1] != 0 )\n",
    "\n",
    "            e2 = np.nonzero(B[a2]) #np.where(A[i2] != 0)\n",
    "            # add the id's where there exists an edge in A \n",
    "            \n",
    "            e3 = np.nonzero(A[b1])\n",
    "            e4 = np.nonzero(B[b2])\n",
    "\n",
    "            # two vertices (a,b) and (c,d) are adjacent if:\n",
    "            # (a,c) in E(G) and (b,h), (d,h) in E(H)\n",
    "            # or (b,d) in E(H) and (a,g), (c,g) in E(G)\n",
    "\n",
    "            a = a1\n",
    "            c = b1\n",
    "            b = a2\n",
    "            d = b2\n",
    "            # if a,c in E(G)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba81e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(2, 1)\n",
      "(2, 2)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(3, 1)\n",
      "(3, 2)\n",
      "(3, 3)\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "list1= [1,2,3]\n",
    "list2 = [1,2,3,4]\n",
    "for i in itertools.product(list1, list2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c249bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w =np.where(list1 ==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ef1423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero([0,1,0,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d47862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from numpy import ComplexWarning\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import multi_dot\n",
    "from scipy.linalg import expm\n",
    "from scipy.sparse.linalg import cg\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "from grakel.kernels import Kernel\n",
    "from grakel.graph import Graph\n",
    "\n",
    "# Python 2/3 cross-compatibility import\n",
    "from builtins import range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad2a6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the class here\n",
    "\n",
    "from grakel.kernels import Kernel\n",
    "\n",
    "def idem(x):\n",
    "    return x\n",
    "\n",
    "class RandomWalk2(Kernel):\n",
    "    \n",
    "    def __init__(self, n_jobs=None,\n",
    "                 normalize=False, verbose=False,\n",
    "                 lamda=0.1, method_type=\"fast\",\n",
    "                 kernel_type=\"geometric\", p=10):\n",
    "        \"\"\"Initialise a random_walk kernel.\"\"\"\n",
    "        \n",
    "        super(RandomWalk2, self).__init__(\n",
    "            n_jobs=n_jobs, normalize=normalize, verbose=verbose)\n",
    "\n",
    "        # Setup method type and define operation.\n",
    "        self.method_type = method_type\n",
    "        self.kernel_type = kernel_type\n",
    "        self.p = p\n",
    "        self.lamda = lamda\n",
    "        \n",
    "        self._initialized.update({\"method_type\": False, \"kernel_type\": False,\n",
    "                                  \"p\": False, \"lamda\": False})\n",
    "        \n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize all transformer arguments, needing initialization.\"\"\"\n",
    "        super(RandomWalk2, self).initialize()\n",
    "        \n",
    "        if not self._initialized[\"method_type\"]:\n",
    "            self._initialized[\"method_type\"] = True\n",
    "            self.add_input_ = idem\n",
    "            \n",
    "            \n",
    "        \n",
    "        # p is the # of steps of the walk -> determine mu_\n",
    "        \n",
    "        \n",
    "    # parse input returns The extracted adjacency matrices for any given input\n",
    "    def parse_input(self, X):\n",
    "        \n",
    "        i = 0\n",
    "        out = list()\n",
    "        print(\"X is\", X)\n",
    "        for (idx, x) in enumerate(iter(X)):\n",
    "\n",
    "            A = x.get_adjacency_matrix()\n",
    "\n",
    "            is_iter = isinstance(x, collections.Iterable)\n",
    "            if is_iter:\n",
    "                x = list(x)\n",
    "            else:\n",
    "                #A = Graph(x[0], {}, {}, self._graph_format).get_adjacency_matrix()\n",
    "                pass\n",
    "\n",
    "            i += 1\n",
    "            out.append(self.add_input_(A))\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def pairwise_operation(self, X, Y):\n",
    "        \n",
    "        XY = np.kron(X, Y)\n",
    "    \n",
    "        # p = number of steps \n",
    "        if self.p:\n",
    "            #S= pow(np.kron(w1.T, w2.T), ell)\n",
    "            S= pow(np.kron(X, Y), self.p)\n",
    "            \n",
    "        print(\"p is \", self.p)\n",
    "        \n",
    "        print(\"X is \", X)\n",
    "        print(\"Y is \" , Y)\n",
    "        \n",
    "        S= pow(np.kron(X, Y), self.p)\n",
    "\n",
    "        return np.sum(S)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45313713",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw2_kernel = RandomWalk2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cf79a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is [<grakel.graph.Graph object at 0x7fbc50881320>]\n",
      "p is  10\n",
      "X is  [[0. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Y is  [[0. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw2_kernel.fit_transform([G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c968334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a214028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit transform calculates kernel matrix \n",
    "# then diagonal\n",
    "\n",
    "\"\"\"if self.normalize:\n",
    "            return km / np.sqrt(np.outer(self._X_diag, self._X_diag))\n",
    "        else:\n",
    "            return km\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow based similarity\n",
    "\n",
    "# assign flow to each edge based on some algorithm \n",
    "\n",
    "# from the source (starting vertex) of random walk to the destination vertex\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import maximum_flow\n",
    "\n",
    "\n",
    "def flow_based_similarity(A, edge_weights):\n",
    "    \n",
    "    # first compute max or min flow and assign to each edge / vertex\n",
    "    \n",
    "    \n",
    "    # compare the edge structure traversed \n",
    "    \n",
    "    \n",
    "\n",
    "#edge scored based similarity \n",
    "\n",
    "# normalize by # edges (?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae047160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centrality \n",
    "# https://networkx.org/documentation/stable/reference/algorithms/centrality.html\n",
    "\n",
    "# ex 1 \n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G1 =nx.Graph()\n",
    "\n",
    "G1.add_nodes_from([1,2,3,4,5])\n",
    "\n",
    "G1.add_edges_from([(2,3),(1,3), (3,4), (3,5)])\n",
    "\n",
    "# ex 2\n",
    "\n",
    "G2 = nx.Graph()\n",
    "G2.add_nodes_from([1,2,3,4,5])\n",
    "\n",
    "G2.add_edges_from([(1,2),(1,3),(2,3),(3,4),(3,5),(4,5)])\n",
    "# ex 3\n",
    "\n",
    "G3 = nx.Graph()\n",
    "\n",
    "G3.add_nodes_from([1,2,3,4,5])\n",
    "\n",
    "G3.add_edges_from([(1,2),(1,3),(3,4),(2,5), (3,5),(4,5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bb8e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.25, 2: 0.25, 3: 1.0, 4: 0.25, 5: 0.25}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from nx.algorithms import degree_centrality\n",
    "\n",
    "nx.degree_centrality(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10204706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.5, 2: 0.5, 3: 1.0, 4: 0.5, 5: 0.5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.degree_centrality(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d22390e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.5, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.degree_centrality(G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88a4a66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.353553316674035,\n",
       " 2: 0.353553316674035,\n",
       " 3: 0.7071069290249942,\n",
       " 4: 0.353553316674035,\n",
       " 5: 0.353553316674035}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.eigenvector_centrality(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10b1db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.3941027427420237,\n",
       " 2: 0.3941027427420237,\n",
       " 3: 0.6154121486068153,\n",
       " 4: 0.3941027427420238,\n",
       " 5: 0.3941027427420238}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.eigenvector_centrality(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a093ae51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.35775191431708964,\n",
       " 2: 0.35775191431708964,\n",
       " 3: 0.5298988890761731,\n",
       " 4: 0.42713167795960844,\n",
       " 5: 0.5298988890761731}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.eigenvector_centrality(G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7112b969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.5714285714285714,\n",
       " 2: 0.5714285714285714,\n",
       " 3: 1.0,\n",
       " 4: 0.5714285714285714,\n",
       " 5: 0.5714285714285714}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.closeness_centrality(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3cfb154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.14285714285714285,\n",
       " 2: 0.14285714285714285,\n",
       " 3: 0.25,\n",
       " 4: 0.14285714285714285,\n",
       " 5: 0.14285714285714285}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.current_flow_closeness_centrality(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21234685",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp1 = nx.current_flow_closeness_centrality(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02e49d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(samp1, key=samp1.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "faf05193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.0, 2: 0.0, 3: 1.0, 4: 0.0, 5: 0.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.betweenness_centrality(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a random walk from the central vertices\n",
    "\n",
    "# locate the max centrality\n",
    "samp1 = nx.current_flow_closeness_centrality(G1)\n",
    "\n",
    "max(samp1, key=samp1.get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e55394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eccentricity sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8dc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the random walks, calc the similarity\n",
    "\n",
    "# given rand walks, calc similarity\n",
    "\n",
    "# sim measure\n",
    "def sim_measure_degree_centrality(walk1, walk2, G1, G2):\n",
    "   \n",
    "    dcent1 = nx.degree_centrality(G1)\n",
    "   \n",
    "    dcent2 = nx.degree_centrality(G2)\n",
    "   \n",
    "    # find the vertices that were traversed\n",
    "    scores1 = []\n",
    "    for v1 in walk1:\n",
    "        c1 = dcent1[v1]\n",
    "        scores1.append(c1)\n",
    "       \n",
    "    scores2 = []\n",
    "    for v2 in walk2:\n",
    "        c2 = dcent2[v2]\n",
    "        scores2.append(c2)\n",
    "       \n",
    "    # compare scores\n",
    "    k = len(walk1)\n",
    "    for i in range(k):\n",
    "        diff= abs(scores1[i] - scores2[i])\n",
    "   \n",
    "    return diff, scores1, scores2\n",
    "\n",
    "\n",
    "# turn this into a kernel score\n",
    "\n",
    "# what makes a kernel score valid? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel that actually computes a walk \n",
    "\n",
    "\n",
    "# within pairwise operation ? or new function\n",
    "def compute_walk(self, X, Y):\n",
    "    \n",
    "    walk1 = []\n",
    "    walk2 = []\n",
    "    \n",
    "    # choose starting vertex \n",
    "    start1= 0\n",
    "    start2 = 0\n",
    "    \n",
    "    n = len(A1)\n",
    "    \n",
    "    wts1 = np.array(weights(A1, q1, beta=2))\n",
    "    wts2 = np.array(weights(A2, q2, beta=2))\n",
    "    \n",
    "    ar = np.arange(n)\n",
    "    for i in range(k):\n",
    "        # compute walk1 \n",
    "        ver1 = A1[start1, :]\n",
    "        ver2 = A2[start2, :]\n",
    "        # choose with probability \n",
    "        \n",
    "        # boolean \n",
    "        #bool1 = n*[False]\n",
    "        #bool2 = n*[False]\n",
    "        bool1 = [i in ver1 for i in ar]\n",
    "        bool2 = [i in ver2 for i in ar]\n",
    "        \n",
    "        p1 = wts1[bool1]\n",
    "        p2 = wts2[bool2]\n",
    "        \n",
    "        # sample with the probability ; idea: multiple walks?\n",
    "        c1= np.random.choice(ver1 , p = p1)\n",
    "        c2 = np.random.choice(ver2, p=p2)\n",
    "        \n",
    "        # jump to c1 \n",
    "        walk1.append(c1)\n",
    "        walk2.append(c2)\n",
    "        \n",
    "        start1 = c1\n",
    "        start2 = c2\n",
    "    \n",
    "    return walk1, walk2\n",
    "\n",
    "# note: how to choose good starting vertices correlated from 2 graphs\n",
    "\n",
    "# note: how to more efficiently compute the walk given the weights matrix ?\n",
    "\n",
    "\n",
    "# then score the similarity of the walks\n",
    "\n",
    "# return a kernel value at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f39f7",
   "metadata": {},
   "source": [
    "fast [geometric]:\n",
    "        Conjugate Gradient method as presented in\n",
    "        :cite:`vishwanathan2006fast` p.12, s.4.2, with\n",
    "        complexity of :math:`O(|E|^{2}rd|V|^{3})` for labeled graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727fa8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check how kroneck prod works\n",
    "# Claculate Kronecker product matrix\n",
    "\n",
    "# X,Y are adj matrices\n",
    "\n",
    "XY = np.zeros(shape=(mn, mn))\n",
    "for k in ck:\n",
    "    XY += np.kron(X[k], Y[k])\n",
    "\n",
    "# XY is a square matrix\n",
    "s = XY.shape[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the kernel on same graph g1 and g2, then with g2 having 1 different edge , 2 different, and so on \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b581152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar=[1,2,3,4,5,6,7,8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "656ff8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nar = np.array(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2dc31369",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4223912574.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/8m/pt7_wvd11vbfl5hhydrtd5t00000gn/T/ipykernel_956/4223912574.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    b1 = [True for i in ver1 else False]\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#nar[{0,1}]\n",
    "ver1 = [2,4,6]\n",
    "b1 = [True for i in ver1 else False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8faf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = 6*[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "207641bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = [i in ver1 for i in ar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "697797da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nar[hi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another library https://github.com/jajupmochi/py-graph\n",
    "\n",
    "# https://github.com/jajupmochi/py-graph/blob/master/pygraph/kernels/randomWalkKernel.py\n",
    "\n",
    "\n",
    "# from spectral decomp method ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferential random walk\n",
    "\n",
    "# define the class here\n",
    "\n",
    "from grakel.kernels import Kernel\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def idem(x):\n",
    "    return x\n",
    "\n",
    "# compute vector q:\n",
    "def compute_q(G):\n",
    "    # use nx\n",
    "    q= nx.degree_centrality(G)\n",
    "    return q\n",
    "\n",
    "# define the weight, given input vector q (quantity assoc to node i)\n",
    "\n",
    "def weights(A, q, beta):\n",
    "    n = len(A)\n",
    "    w = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            w[i,j] = np.pow(q[i]*q[j], beta)*A[i,j]\n",
    "    \n",
    "    return w\n",
    "\n",
    "def compute_walk(self, X, Y):\n",
    "    \n",
    "    walk1 = []\n",
    "    walk2 = []\n",
    "    \n",
    "    # choose starting vertex \n",
    "    start1= 0\n",
    "    start2 = 0\n",
    "    \n",
    "    n = len(A1)\n",
    "    \n",
    "    wts1 = np.array(weights(A1, q1, beta=2))\n",
    "    wts2 = np.array(weights(A2, q2, beta=2))\n",
    "    \n",
    "    ar = np.arange(n)\n",
    "    for i in range(k):\n",
    "        # compute walk1 \n",
    "        ver1 = A1[start1, :]\n",
    "        ver2 = A2[start2, :]\n",
    "        # choose with probability \n",
    "        \n",
    "        # boolean \n",
    "        #bool1 = n*[False]\n",
    "        #bool2 = n*[False]\n",
    "        bool1 = [i in ver1 for i in ar]\n",
    "        bool2 = [i in ver2 for i in ar]\n",
    "        \n",
    "        p1 = wts1[bool1]\n",
    "        p2 = wts2[bool2]\n",
    "        \n",
    "        # sample with the probability ; idea: multiple walks?\n",
    "        c1= np.random.choice(ver1 , p = p1)\n",
    "        c2 = np.random.choice(ver2, p=p2)\n",
    "        \n",
    "        # jump to c1 \n",
    "        walk1.append(c1)\n",
    "        walk2.append(c2)\n",
    "        \n",
    "        start1 = c1\n",
    "        start2 = c2\n",
    "    \n",
    "    return walk1, walk2\n",
    "\n",
    "class RandomWalk3(Kernel):\n",
    "    \n",
    "    def __init__(self, n_jobs=None,\n",
    "                 normalize=False, verbose=False,\n",
    "                 lamda=0.1, beta=2, method_type=\"fast\",\n",
    "                 kernel_type=\"geometric\", p=10):\n",
    "        \"\"\"Initialise a random_walk kernel.\"\"\"\n",
    "        \n",
    "        super(RandomWalk2, self).__init__(\n",
    "            n_jobs=n_jobs, normalize=normalize, verbose=verbose)\n",
    "\n",
    "        # Setup method type and define operation.\n",
    "        self.method_type = method_type\n",
    "        self.kernel_type = kernel_type\n",
    "        self.p = p\n",
    "        self.lamda = lamda\n",
    "        \n",
    "        self.beta = beta\n",
    "        \n",
    "        # save network x version of the graph\n",
    "        self.networkx_graph = nx.Graph()\n",
    "        \n",
    "        self.numnodes = 0\n",
    "        \n",
    "        self.edge_list =[]\n",
    "        \n",
    "        self.weight_vec = []\n",
    "    \n",
    "        self._initialized.update({\"method_type\": False, \"kernel_type\": False,\n",
    "                                  \"p\": False, \"lamda\": False})\n",
    "        \n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize all transformer arguments, needing initialization.\"\"\"\n",
    "        super(RandomWalk2, self).initialize()\n",
    "        \n",
    "        if not self._initialized[\"method_type\"]:\n",
    "            self._initialized[\"method_type\"] = True\n",
    "            self.add_input_ = idem\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        # p is the # of steps of the walk -> determine mu_\n",
    "        \n",
    "    def custom_initialize_parse(self,X):\n",
    "        # set the networkx graph and other parameters\n",
    "        g1 = nx.Graph()\n",
    "        \n",
    "        \n",
    "        \n",
    "        for (idx, x) in enumerate(iter(X)):\n",
    "\n",
    "            A = x.get_adjacency_matrix()\n",
    "            n = len(A)\n",
    "            \n",
    "            nodes= np.arange(n)\n",
    "            g1.add_nodes_from(nodes)\n",
    "\n",
    "            g1.add_edges_from(edge_list) # [(2,3),(1,3), (3,4), (3,5)])\n",
    "            \n",
    "            q = compute_q(g1) # from nx\n",
    "            \n",
    "            self.weight_vec = weights(A, q, self.beta)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    # parse input returns The extracted adjacency matrices for any given input\n",
    "    def parse_input(self, X):\n",
    "        \n",
    "        i = 0\n",
    "        out = list()\n",
    "        print(\"X is\", X)\n",
    "        for (idx, x) in enumerate(iter(X)):\n",
    "\n",
    "            A = x.get_adjacency_matrix()\n",
    "            \n",
    "            # test this by printing\n",
    "            print(\"parse input A is:\", A)\n",
    "\n",
    "            is_iter = isinstance(x, collections.Iterable)\n",
    "            if is_iter:\n",
    "                x = list(x)\n",
    "            else:\n",
    "                #A = Graph(x[0], {}, {}, self._graph_format).get_adjacency_matrix()\n",
    "                pass\n",
    "\n",
    "            i += 1\n",
    "            out.append(self.add_input_(A))\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def pairwise_operation(self, X, Y):\n",
    "        \n",
    "        XY = np.kron(X, Y)\n",
    "    \n",
    "        # p = number of steps \n",
    "        if self.p:\n",
    "            #S= pow(np.kron(w1.T, w2.T), ell)\n",
    "            S= pow(np.kron(X, Y), self.p)\n",
    "            \n",
    "        print(\"p is \", self.p)\n",
    "        \n",
    "        print(\"X is \", X)\n",
    "        print(\"Y is \" , Y)\n",
    "        \n",
    "        S= pow(np.kron(X, Y), self.p)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if doing random walk manually\n",
    "        if self.kernel_type == 'manual':\n",
    "            walk1, walk2 = compute_walk(self, X, Y)\n",
    "            \n",
    "            # score the walks \n",
    "            \n",
    "\n",
    "        return np.sum(S)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual random walk binary (tree form)\n",
    "\n",
    "# next: find faster / more efficient random walk algorithm\n",
    "\n",
    "def compute_walk_binary(self, X, Y):\n",
    "    \n",
    "    walks1=[]\n",
    "    walks2=[]\n",
    "    \n",
    "    walk1 = []\n",
    "    walk2 = []\n",
    "    \n",
    "    # choose starting vertex \n",
    "    start1= 0\n",
    "    start2 = 0\n",
    "    \n",
    "    n = len(A1)\n",
    "    \n",
    "    wts1 = np.array(weights(A1, q1, beta=2))\n",
    "    wts2 = np.array(weights(A2, q2, beta=2))\n",
    "    \n",
    "    ar = np.arange(n)\n",
    "    for i in range(k):\n",
    "        # compute walk1 \n",
    "        ver1 = A1[start1, :]\n",
    "        ver2 = A2[start2, :]\n",
    "        # choose with probability \n",
    "        \n",
    "        # boolean \n",
    "        #bool1 = n*[False]\n",
    "        #bool2 = n*[False]\n",
    "        bool1 = [i in ver1 for i in ar]\n",
    "        bool2 = [i in ver2 for i in ar]\n",
    "        \n",
    "        p1 = wts1[bool1]\n",
    "        p2 = wts2[bool2]\n",
    "        \n",
    "        # sample with the probability ; idea: multiple walks?\n",
    "        c1= np.random.choice(ver1 , p = p1)\n",
    "        # sample again with the probability\n",
    "        c1again = np.random.choice(ver1 , p = p1)\n",
    "        \n",
    "        c2 = np.random.choice(ver2, p=p2)\n",
    "        \n",
    "        c2again= np.random.choice(ver2, p=p2)\n",
    "        \n",
    "        # jump to c1 \n",
    "        walk1.append(c1)\n",
    "        walk2.append(c2)\n",
    "        \n",
    "        start1 = c1\n",
    "        start2 = c2\n",
    "    \n",
    "    return walk1, walk2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate : v -> e property\n",
    "\n",
    "# flow, centrality of edge?\n",
    "\n",
    "def vertex_to_edge_centrality(cent_list, edge_mat):\n",
    "    # for each edge, take the average of the 2 vertices it connects \n",
    "    n = len(edge_mat)\n",
    "    edge_cent = []\n",
    "    edge_cent_mat = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # look up centrality of i and j\n",
    "            ci = cent_list[i]\n",
    "            cj = cent_list[j]\n",
    "            av = np.mean(ci, cj)\n",
    "            edge_cent_mat[i,j] = av\n",
    "    \n",
    "    return edge_cent_mat\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many random walks are needed for good comparison ? \n",
    "\n",
    "# analyze how many unique paths based on cycles (bases)?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
